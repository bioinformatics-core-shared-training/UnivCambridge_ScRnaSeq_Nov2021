---
title: "CRUK CI Summer School 2021 - introduction to single-cell RNA-seq analysis"
subtitle: 'Quality Control'
author: "Stephane Ballereau, Ashley Sawle"
output:
  html_document:
    df_print: paged
    toc: yes
    number_sections: true
    code_folding: hide
---

```{r setup, echo=FALSE, include=FALSE, message=FALSE}
library(DT)
library(knitr)
opts_chunk$set(error=FALSE, message=FALSE, warning=FALSE, cache=TRUE)
opts_chunk$set(fig.width=7, fig.height=7)
opts_chunk$set(dev="CairoPNG")
set.seed(123)
```

# Introduction {#PreProcTop}

<!--
OSCA chapter 6 Quality Control
-->

We will use two sets of Bone Marrow Mononuclear Cells (BMMC):

* 'CaronBourque2020': pediatric samples
* 'HCA': HCA Census of Immune Cells for adult BMMCs

Fastq files were retrieved from publicly available archive (SRA and HCA). 

Sequencing quality was assessed and visualised using fastQC and MultiQC.

Reads were aligned against GRCh38 and features counted using cellranger (v3.1.0).

We will now check the quality of the data further:

* Mapping quality
* Cell counts
* Distribution of keys quality metrics

We will then:

* Filter genes with very low expression
* Identify low-quality cells
* Filter and/or mark low quality cells

# Load packages

```{r libraries_preProc}
library(DropletUtils)
library(scater)
library(ensembldb)
library(AnnotationHub)
library(BiocParallel)
library(tidyverse)
library(patchwork)
library(ggvenn)
```

* **DropletUtils** - utilities for the analysis of droplet-based, inc. cell counting
* **scater** - QC
* **ensembldb** & **AnnotationHub** - for gene annotation
* **BiocParallel** - for parallelisation of some functions
* **tidyverse**, **patchwork** & **ggvenn** - for data.frame manipulation and plotting

#  Load the data

## Sample meta data

We will load both the Caron and HCA data sets. We have already prepared a sample
meta data table that relates the sample/run ID to the sample group.

```{r samplesheet_preProc, message=FALSE}
samplesheet <- read_tsv("Data/sample_sheet.tsv")
```

```{r samplesheet_display_preProc, echo=FALSE}
samplesheet %>%
	as.data.frame() %>%
	datatable(rownames = FALSE, options = list(dom="tpl", nrows=20))
```

## The scRNAseq count data from CellRanger

We will load the data for the **SRR9264343**. To load the data from the 
CellRanger outputs, we need to use the function `read10xCounts` from the
`DropletUtils` package. 

### Parallelisation

scRNAseq data sets tend to be very large and processing them requires a large
amount of computing power and can take time. Many of the commands we will use
have the option to be run in parallels across multiple processors. By default 
they will only use a single processor, but parallelisation will greatly speed
up the analysis. 

We need to first set up some parallel parameters using the 
package [`BiocParallel`](https://bioconductor.org/packages/release/bioc/vignettes/BiocParallel/inst/doc/Introduction_To_BiocParallel.pdf).

```{r}
bp.params <- MulticoreParam(workers = 7)
```

Here were are selecting to use forked processes with `MulticoreParam` and 
instructing the function to use 7 cores (our machines have 8, this leaves 1 to
run the desktop etc.) Note that on Windows `MulticoreParam` does not work and 
it is necessary to use `SnowParam` - please refer to the `BiocParallel` 
vignettes for further information.

### Loading a single sample

We pass the function the location of the directory containing the counts matrix,
cell barcodes and features (genes). In this case we will load the raw matrix.

```{r example_load}
sample.path <- "CellRanger_Outputs/SRR9264343/outs/raw_feature_bc_matrix/"
sce.raw <- read10xCounts(sample.path, col.names=TRUE, BPPARAM = bp.params)
sce.raw
```

### The `SingleCellExperiment` object

The data has been loaded as a
[SingleCellExperiment](https://bioconductor.org/packages/SingleCellExperiment/)
object. The details of the structure of the object are described
[here](https://www.nature.com/articles/s41592-019-0654-x). In summary, it stores
various data types in a single object. Currently it will contain:

* the count matrix
* feature (gene) metadata
* cell (droplet) metadata

Later we will also add the outcomes of downstream analysis such as
dimensionality reduction.

![](Images/sceOverview.png)

### The counts matrix

Compared to bulk RNA-seq, Single-cell RNA-seq data is sparse, i.e. there many
missing values or zeroes.  This is particularly true with droplet-based methods
such as 10X, mostly because:

* any given cell does not express each gene
* the library preparation does not capture all transcript the cell does express
* the sequencing depth per cell is far lower and so fewer of the expressed genes
are detected

We can access the counts matrix with `counts`. Given the large number of
droplets in a sample, count matrices can be large. 

```{r example_dim}
dim(counts(sce.raw))
```

They are however very sparse, that is, most of the entries are 0's. To save
memory the counts can be stored in a 'sparse matrix' that only stores non-zero
values, for example a `dgCMatrix` object.

```{r countsMatrix}
counts(sce.raw)[1:10, 1:10]
```


### Features

Details about the "features" (in this case genes) can by accessed using the 
`rowData` function. Currently it contains the ensembl gene ID and the gene 
symbol, which have been derived from the 10x reference used by CellRanger. It
also contains a "Type" column, which tells us what sort of data we are looking
at; in this case it is "Expression" for gene expression. If we wish to, we can
add further annotation to the features by adding extra columns to this data 
frame.

```{r example_row}
head(rowData(sce.raw))
```

### Droplet annotation

Details about the droplets can be accessed using `colData`. Currently it
contains the sample names and droplet Barcodes. As with the feature data, we can
add additional information about each droplet, e.g. counts of genes or the
percentage of mitochondrial genes, to this data frame. The rows of this table 
correspond to the data in the columns of the count matrix; the row names of this
table will match the column names of the counts matrix - currently these are the 
droplet barcodes.

```{r example_col}
head(colData(sce.raw))
```

```{r}
colnames(as.matrix(counts(sce.raw)[1:2,1:6]))
```


```{r, echo=FALSE}
ncolRaw <- ncol(sce.raw)
rm(sce.raw)
```


## Load filtered matrices

In the previous example we loaded the _raw_ matrix, in fact we are going to work
with the _filtered_ matrix, which only contains droplets called as cells by 
CellRanger. After this we will apply some additional QC steps to these droplets
in order to remove any that we are not confident contain a real cell or those 
that we think contain multiple cells.

We can load multiple samples at the same time using the `read10xCounts` command.
This will create a single object containing the data for multiple samples. We
can then QC and filter the samples in conjunction. As we will see later, this is 
not always optimal when samples have been processed in multiple batches.

As an example, we will begin by loading 2 samples from each sample group. This
time we will start with the filtered counts matrix, which only contains cells
called by CellRanger. We pass the `read10xCounts` a named vector containing the
paths to the filtered counts matrices that we wish to load; the names of the
vector will be used as the sample names in the Single Cell Experiment object.

Note that for PBMMC_1 we have two sequencing runs, for now, we will only use one
of them.

```{r make_file_list}
list_of_files <- samplesheet %>%
    distinct(SampleName, .keep_all = TRUE) %>% 
    group_by(SampleGroup) %>% 
    slice(1:2) %>%
    mutate(File=str_c("CellRanger_Outputs/", 
                      SampleId,
                      "/outs/filtered_feature_bc_matrix")) %>%
    pull(File, SampleId)
list_of_files
```
    
```{r load_data_sets}           
sce <- read10xCounts(list_of_files, col.names=TRUE, BPPARAM = bp.params)
sce
```

If you compare the dimensions of this object to those of the raw object above, 
you will see that whereas the raw object that **`r ncolRaw`** columns, the 
filtered object only has **`r ncol(sce)`** columns.

# Modify the droplet annotation

Currently, the droplet annotation in `colData` slot of the `sce` object has two
columns: "Sample" and "Barcode". The "Sample" is the name of the sample as we
provided it to `read10xCounts`, the "Barcode" is the barcode for the droplet 
(cell). 

```{r}
colData(sce)
```

The "Barcode" column contains the cell/droplet barcode and comprises the actual
sequence and a 'group ID', e.g. AAACCTGAGAAACCAT-1. The 'group ID' helps
distinguish cells from different samples that have identical barcode sequences,
however, as each sample was processed separately with CellRanger, the group ID
is set to 1 in all data sets. Some of our downstream tools will use this column
to identify different droplets, so we will need modify these to be unique.

In order to distinguish droplets that originate from different samples but have
the same barcode, `read10XCounts` has added the "index" of the sample in
the `list_of_files` object (1-10) to the beginning of the cell barcode in the
row names of the droplet annotation table and the column names of the count 
matrix. We will use this number to modify the "Barcode" column.

We will also switch the "Sample" column to be the sample name and add 
information from the sample sheet to the droplet annotation.

```{r dataSets_addSampleSheet}
colData(sce) <- colData(sce) %>% 
    as.data.frame() %>%
    rownames_to_column("RowName") %>% 
    mutate(SampleNum = str_extract(RowName, "^[0-9]+")) %>%
    mutate(Barcode = str_replace(Barcode, "1$", SampleNum)) %>%
    left_join(samplesheet, by=c(Sample="SampleId")) %>%
    rename(SampleId=Sample) %>% 
    rename(Sample=SampleName) %>% 
    column_to_rownames("RowName") %>% 
    select(Sample, Barcode, SampleId, SampleGroup, DatasetName) %>%
    DataFrame()
```

```{r}
colData(sce)
```

# Properties of scRNA-seq data

## Number of genes detected per cell

The number and identity of genes detected in a cell vary greatly across cells:
the total number of genes detected across all cells is far larger than the
number of genes detected in each cell.

```{r echo=FALSE}
genesPerCell <- colSums(counts(sce) > 0)
```

For the current set of samples the total number of genes detected across cells
was `r sum(rowSums(counts(sce)) > 0)` out of `r nrow(sce)` gene in the 
reference, but if we look at the number of genes 
detected in each cell, we can see that this ranges from `r min(genesPerCell)` to
`r max(genesPerCell)`, with a median of `r median(genesPerCell)`.

```{r properties_distribNbGenesDetected}
genesPerCell <- colSums(counts(sce) > 0)
summary(genesPerCell)

plot(density(genesPerCell), main="", xlab="Genes per cell")
```

## Total UMI for a gene versus the number of times detected

If we compare the number of UMI's assigned to an individual gene to the number
of cells in which that gene is detected, we can see that highly expressed genes
tend to be detected in a higher proportion of cells than lowly expressed genes.

```{r}
set.seed(232)
tmpCounts <- counts(sce)[,sample(ncol(sce), 1000)]

plot(rowSums(tmpCounts),
     rowMeans(tmpCounts > 0),
     log = "x",
     xlab="total number of UMIs",
     ylab="proportion of cells expressing the gene"
)
rm(tmpCounts)
```

## Distribution of counts for a gene across cells

We could also look at the distribution of counts for individual genes across all
cells. The plot below shows this distribution for the top 20 genes detected.

```{r}
rel_expression <- t( t(counts(sce)) / colSums(counts(sce))) * 100
rownames(rel_expression) <- rowData(sce)$Symbol
most_expressed <- sort(rowSums( rel_expression ),T)[20:1]
plot_data <- as.matrix(t(rel_expression[names(most_expressed),]))

boxplot(plot_data, cex=0.1, las=1, xlab="% total count per cell", horizontal=TRUE)
```

```{r echo=FALSE}
rm(rel_expression, plot_data)
```

## Undetected genes

Although the count matrix has `r nrow(sce)` genes, many of these will not have
been detected in any droplet.

```{r detected_genes}
detected_genes <- rowSums(counts(sce)) > 0
table(detected_genes)
```

About a fifth of the genes have not been detected in any droplet. We can 
remove these before proceeding in order to reduce the size of the single cell
experiment object.

```{r remove_undetected_genes}
sce <- sce[detected_genes,]
```


# Quality control

<!-- https://osca.bioconductor.org/quality-control.html -->

The cell calling performed by CellRanger does not always retain only droplets
containing cells. Poor-quality cells, or rather droplets, may be caused
by cell damage during dissociation or failed library preparation. They usually
have low UMI counts, few genes detected and/or high mitochondrial content. The
presence of these droplets in the data set may affect normalisation, assessment
of cell population heterogeneity, clustering and trajectory:

* Normalisation: Contaminating genes, 'the ambient RNA', are detected at low
levels in all libraires. In low quality libraries with low RNA content, scaling
will increase counts for these genes more than for better-quality cells,
resulting in their apparent upregulation in these cells and increased variance
overall.  
* Cell population heterogeneity: variance estimation and dimensionality
reduction with PCA where the first principal component will be correlated with
library size, rather than biology.  
* Clustering and trajectory: higher mitochondrial and/or nuclear RNA content may
cause low-quality cells to cluster separately or form states or trajectories
between distinct cell types.  

In order to remove or reduce the impact of poor-quality droplets on our 
downstream analysis we will attempt to filter them out using some QC metrics.
The three principle means of doing this are to apply thresholds for inclusion
on three characteristics:

* The **library size** defined as the total sum of UMI counts across all genes;
  cells with small library sizes are considered to be of low quality as the RNA
  has not been efficiently captured, i.e. converted into cDNA and amplified,
  during library preparation.

* The **number of expressed genes in each cell** defined as the number of genes
  with non-zero counts for that cell; any cell with very few expressed genes is
  likely to be of poor quality as the diverse transcript population has not
  been successfully captured.

* The **proportion of UMIs mapped to genes in the mitochondrial genome**; high
  proportions are indicative of poor-quality cells, possibly because of loss of
  cytoplasmic RNA from perforated cells (the reasoning is that mitochondria are
  larger than individual transcript molecules and less likely to escape through
  tears in the cell membrane).

The [scater](https://bioconductor.org/packages/3.11/bioc/html/scater.html)
function `addPerCellQC()` will compute various per droplet QC metrics and will
add this information as new columns in the droplet annotation (`colData`) of the
single cell object.

### Annotate genes

In order to assess the percentage of mitochondrial UMIs, we will need to be
able to identify mitochondrial genes. The simplest way to do this is to annotate
the genes with their chromosome of origin.

There are many ways we could annotate our genes in R. We will use 
`AnnotationHub`.

```{r annotate_genes}
ah <- AnnotationHub()
ens.mm.98 <- query(ah, c("Homo sapiens", "EnsDb", 98))[[1]] 

genes <- rowData(sce)$ID
gene_annot <- AnnotationDbi::select(ens.mm.98, 
                                    keys = genes,
                                    keytype = "GENEID",
                                    columns = c("GENEID", "SEQNAME")) %>%
    set_names(c("ID", "Chromosome"))
rowData(sce) <- merge(rowData(sce), gene_annot, by = "ID", sort=FALSE)
rownames(rowData(sce)) <- rowData(sce)$ID

rowData(sce)
```

Number of genes per chromosome, including 13 on the mitochondrial genome:

```{r qc_mitoGenes}
rowData(sce) %>%
	as.data.frame() %>%
	count(Chromosome, name = "Number of Genes") %>%
	datatable(rownames = FALSE)
```

### Add per cell QC metrics

We can add the per cell QC metrics to the droplet annotation using the function
`addPerCellQC`. In order to get the percentage of mitochondrial UMIs in each
cell, we need to pass the function a vector indicating which genes are
mitochondrial.

```{r qc_addPerCellQC}
is.mito <- which(rowData(sce)$Chromosome=="MT")

sce <- addPerCellQC(sce, subsets=list(Mito=is.mito), BPPARAM = bp.params)
```

The function has added six columns to the droplet annotation:

* **sum**: total UMI count
* **detected**: number of features (genes) detected
* **subsets_Mito_sum**: number of UMIs mapped to mitochondrial transcripts
* **subsets_Mito_detected**: number of mitochondrial genes detected
* **subsets_Mito_percent**: percentage of UMIs mapped to mitochondrial transcripts
* **total**: also the total UMI count

We will use **sum**, **detected**, and **subsets_Mito_percent** to further
filter the cells.

```{r qc_addPerCellQCTab, eval=TRUE}
head(colData(sce)) %>%
	as.data.frame() %>%
	datatable(rownames = FALSE)
```

## QC metric distribution

Before moving on to do the actual cell filtering, it is always a good idea to
explore the distribution of the metrics across the droplets.

First let's look across all cells in the data set.

```{r qc_metricDistrib_twoHist, fig.width=12, fig.height=5}
par(mfrow=c(1, 3))
hist(log10(sce$sum),
     breaks=20,
     col="grey80",
     xlab="log10(Total UMI count)",
     main="")
hist(sce$detected,
     breaks=20,
     col="grey80",
     xlab="Total genes detected",
     main="")
hist(sce$subsets_Mito_percent,
     breaks=20,
     col="grey80",
     xlab="Proportion of reads in mitochondrial genes",
     main="")
```

This gives us an overview of all the cells in the experiment, but to get a
better idea we need to have a look at these distributions on a per sample basis.
The `scater` function `plotColData` provides a simple interface for generating
these plots.

```{r qc_metricDistrib_plotColData_write, fig.width=12, fig.height=14}
p1 <- plotColData(sce, x="Sample", y="sum",other_fields="SampleGroup") + 
        facet_wrap(~SampleGroup, nrow=1, scales = "free_x") + 
        scale_y_log10() + 
        ggtitle("Total count")
p2 <- plotColData(sce, x="Sample", y="detected", other_fields="SampleGroup") + 
        facet_wrap(~SampleGroup, nrow=1, scales = "free_x") + 
        scale_y_log10() + 
        ggtitle("Detected features")
p3 <- plotColData(sce, x="Sample", y="subsets_Mito_percent", other_fields="SampleGroup") + 
        facet_wrap(~SampleGroup, nrow=1, scales = "free_x") +
        ggtitle("Mito percent")

p1 / p2 / p3
```

A scatter plot shows the extent to which library size and numbers of genes
detected are correlated.

```{r, fig.width=10, fig.height=6}
ggplot(data.frame(colData(sce)),
             aes(x=sum,
                 y=detected,
                 col=subsets_Mito_percent)) +
  geom_point() + 
    facet_wrap(~SampleGroup)
```

# Identification of low-quality cells with adaptive thresholds

One can use hard threshold for the library size, number of genes detected and
mitochondrial content. These will however vary across runs. It may therefore be
preferable to rely on outlier detection to identify cells that markedly differ
from most cells.

We saw above that the distribution of the QC metrics is close to Normal. Hence,
we can detect outliers using the median and the median absolute deviation (MAD)
from the median (not the mean and the standard deviation that both are sensitive
to outliers).

For a given metric, an outlier value is one that lies over some number of MADs
away from the median. A cell will be excluded if it is an outlier in the part of
the range to avoid, for example low gene counts, or high mitochondrial content.
For a normal distribution, a threshold defined with a distance of 3 MADs from
the median retains about 99% of values.

The `scater` function `isOutlier` can be used to detect outlier cells based on
any metric in the `colData` table. It returns a boolean vector which identifies
outliers. By default it will mark any cell that is 3 MADS in either direction
from the median as an outlier.

## Library size

With library size we wish to identify outliers that have very low library sizes,
this indicates that the droplets either contain poor quality cells, perhaps
damaged or dying, or do not contain a cell at all.

The library size distribution tends to have a long tail to the right (small
numbers of cells with very high UMI counts). We therefore log transform the
library size in order to the make the distribution closer to normal. This 
also improves the resolution of the smaller library sizes and ensures that we do
not end up with negative threshold.

```{r adapThresTab_libSize}
low_lib_size <- isOutlier(sce$sum, log=TRUE, type="lower")
table(low_lib_size)
```

This has excluded `r sum(low_lib_size)` cells. We can view the threshold
values to check that they seem reasonable.

```{r adapThresVal_libSize}
attr(low_lib_size, "thresholds")[1]
```

We can view the effect of the filtering using `plotColData`.

```{r, fig.width=12, fig.height=5}
colData(sce)$low_lib_size <- low_lib_size
plotColData(sce, 
            x="Sample", 
            y="sum",
            other_fields="SampleGroup", 
            colour_by = "low_lib_size") + 
    facet_wrap(~SampleGroup, nrow=1, scales = "free_x") + 
    scale_y_log10() + 
    labs(y = "Total count", title = "Total count") +
    guides(colour=guide_legend(title="Discarded"))
```

## Number of genes

As with the library size, we will log tranform the number of genes detected 
prior to filtering using the median absolute deviation.

````{r adapThresTab_detected}
low_n_features <- isOutlier(sce$detected, log=TRUE, type="lower")
table(low_n_features)
```

This has filter out 444 cells. The threshold value was:

```{r adapThresVal_detected}
attr(low_n_features, "thresholds")[1]
```

We can view the effect of the filtering using `plotColData`.

```{r, fig.width=12, fig.height=5}
colData(sce)$low_n_features <- low_n_features
plotColData(sce, 
            x="Sample", 
            y="detected",
            other_fields="SampleGroup", 
            colour_by = "low_n_features") + 
    facet_wrap(~SampleGroup, nrow=1, scales = "free_x") + 
    scale_y_log10() + 
    labs(y = "Genes detected", title = "Genes detected") +
    guides(colour=guide_legend(title="Discarded"))
```

## Mitochondrial content

For the mitochondrial content the exclusion zone is in the higher part of the 
distribution. For this reason we do not need to worry about log transforming the
data as want to remove the long right hand tail anyway.

```{r adapThresTab_mito}
high_Mito_percent <- isOutlier(sce$subsets_Mito_percent, type="higher")
table(high_Mito_percent)
```

This has removed 5422 cells in total. The upper threshold value:

```{r adapThresVal_mito}
attr(high_Mito_percent, "thresholds")[2]
```

We can view the effect of the filtering using `plotColData`.

```{r, fig.width=12, fig.height=5}
colData(sce)$high_Mito_percent <- high_Mito_percent
plotColData(sce,  
            x="Sample",
            y="subsets_Mito_percent",
            other_fields="SampleGroup",
            colour_by = "high_Mito_percent") + 
    facet_wrap(~SampleGroup, nrow=1, scales = "free_x") + 
    labs(y = "Percentage mitochondrial UMIs",
         title = "Mitochondrial UMIs") +
    guides(colour=guide_legend(title="Discarded"))
```

## Summary of discarded cells

Having applied each of the three thresholds separately, we can now combind them
to see how many droplets in total we will be excluding.

```{r adapThres_summary}
tibble(`Library Size`=sum(low_lib_size),
       `Genes detected`=sum(low_n_features),
       `Mitochondrial UMIs`=sum(high_Mito_percent),
       Total=sum(low_lib_size | low_n_features | high_Mito_percent)) %>% 
    datatable(rownames = FALSE, options = list(dom="t"))
```
Clearly there is some overlap, as we would expect. We can visualise this with a
Venn diagram.

```{r, fig.width=6, fig.height=6}
colData(sce) %>% 
    as.data.frame() %>% 
    dplyr::select(`Library Size`=low_lib_size,
           `Genes detected`=low_n_features,
           `Mitochondrial UMIs`=high_Mito_percent) %>% 
    ggvenn(show_percentage = FALSE)
```

## All three filter steps at once

The three steps above may be run in one go using the `quickPerCellQC` function.

```{r adapThres_quickPerCellQC}
reasons <- quickPerCellQC(colData(sce),
			  percent_subsets=c("subsets_Mito_percent"))

as.data.frame(reasons) %>%
    summarise(across(everything(), sum)) %>% 
    dplyr::select(`Library Size`=low_lib_size,
                  `Genes detected`=low_n_features,
                  `Mitochondrial UMIs`=high_subsets_Mito_percent,
                  Total=discard) %>% 
    datatable(rownames = FALSE, options = list(dom="t"))
```

## Assumptions

Data quality depends on the tissue analysed, some being difficult to dissociate,
e.g. brain, so that one level of QC stringency will not fit all data sets.

Filtering based on QC metrics as done here assumes that these QC metrics are not
correlated with biology. This may not necessarily be true in highly heterogenous
data sets where some cell types represented by good-quality cells may have low
RNA content or high mitochondrial content.

# Considering experimental factors when filtering

The two data sets analysed here may have been obtained in experiments with
different settings, such as cell preparation or sequencing depth. Such
differences between these two batches would affect the adaptive thesholds
discussed above - that is, the distributions of the metrics may be different in
each batch and so we should really apply the adaptive thresholding separately
for each batch. The `quickPerCellQC` has a "batch" argument that allows us to 
specify with samples belong to which batches. The batches are then filtered
independently.

We will first need to add a "batch" column to the droplet annotation that 
identifies samples from the Caron paper and samples from the HCA.

```{r quickPerCellQC_batch_compute}
batch.reasons <- quickPerCellQC(colData(sce),
                                percent_subsets=c("subsets_Mito_percent"),
                                batch=sce$DatasetName)

as.data.frame(batch.reasons) %>%
    summarise(across(everything(), sum)) %>% 
    dplyr::select(`Library Size`=low_lib_size,
                  `Genes detected`=low_n_features,
                  `Mitochondrial UMIs`=high_subsets_Mito_percent,
                  Total=discard) %>% 
    datatable(rownames = FALSE, options = list(dom="t"))
```

The table below shows how the thresholds for each metric differ between the
batch-wise analysis and the analysis using all samples.

```{r}
all.thresholds <- tibble(`Batch`="All",
       `Library Size`=attr(reasons$low_lib_size, "thresholds")[1],
       `Genes detected`=attr(reasons$low_n_features, "thresholds")[1],
       `Mitochondrial UMIs`=attr(reasons$high_subsets_Mito_percent, "thresholds")[2])


tibble(`Batch`=names(attr(batch.reasons$low_lib_size, "thresholds")[1,]),
       `Library Size`=attr(batch.reasons$low_lib_size, "thresholds")[1,],
       `Genes detected`=attr(batch.reasons$low_n_features, "thresholds")[1,],
       `Mitochondrial UMIs`=attr(batch.reasons$high_subsets_Mito_percent, "thresholds")[2,]) %>% 
    bind_rows(all.thresholds) %>% 
    mutate(across(where(is.numeric), round, digits=2)) %>% 
    datatable(rownames = FALSE, options = list(dom="t"))
```

Let's replace the columns in the droplet annotation with these new filters.

```{r quickPerCellQC_batch_replace}
sce$low_lib_size <- batch.reasons$low_lib_size
sce$low_n_features <- batch.reasons$low_n_features
sce$high_Mito_percent <- batch.reasons$high_subsets_Mito_percent
sce$discard <- batch.reasons$discard
```

We can visualise how the new filters look using violin plots.

```{r, fig.width=12, fig.height=12}
p.lib <- plotColData(sce, 
            x="Sample", 
            y="sum",
            other_fields="SampleGroup", 
            colour_by = "low_lib_size") + 
        facet_wrap(~SampleGroup, nrow=1, scales = "free_x") + 
        scale_y_log10() + 
        labs(y = "Total count", title = "Total count") +
        guides(colour=guide_legend(title="Discarded"))


p.ng <- plotColData(sce, 
            x="Sample", 
            y="detected",
            other_fields="SampleGroup", 
            colour_by = "low_n_features") + 
        facet_wrap(~SampleGroup, nrow=1, scales = "free_x") + 
        scale_y_log10() + 
        labs(y = "Genes detected", title = "Genes detected") +
        guides(colour=guide_legend(title="Discarded"))


p.mt <- plotColData(sce, 
            x="Sample", 
            y="subsets_Mito_percent",
            other_fields="SampleGroup", 
            colour_by = "high_Mito_percent") + 
        facet_wrap(~SampleGroup, nrow=1, scales = "free_x") + 
        labs(y = "Percentage mitochondrial UMIs",
             title = "Mitochondrial UMIs") +
        guides(colour=guide_legend(title="Discarded"))

p.lib / p.ng / p.mt
```

There are some distinct differences, most noticeable is that there is now no
filtering using library size. The venn diagrams below show how the number of
discarded droplets in HCA and Caron have changed for each filter in comparison
to when the MAD filtering was applied across all samples.

```{r, fig.width=12, fig.height=8}
libDat <- tibble(`All together`=reasons$low_lib_size, 
                 `By batch`=batch.reasons$low_lib_size,
                 Batch=sce$DatasetName)
    
ph1 <- libDat %>% 
    dplyr::filter(Batch=="HCA") %>% 
    ggvenn(show_percentage = FALSE) +
        labs(title="Library Size - HCA")
pc1 <- libDat %>% 
    dplyr::filter(Batch=="Caron") %>% 
    ggvenn(show_percentage = FALSE) +
        labs(title="Library Size - Caron")

nGenDat <- tibble(`All together`=reasons$low_n_features, 
                  `By batch`=batch.reasons$low_n_features,
                 Batch=sce$DatasetName)
ph2 <- nGenDat %>% 
    dplyr::filter(Batch=="HCA") %>% 
        ggvenn(show_percentage = FALSE) +
            labs(title="Genes detected - HCA")
pc2 <- nGenDat %>% 
    dplyr::filter(Batch=="Caron") %>% 
           ggvenn(show_percentage = FALSE) +
            labs(title="Genes detected - Caron")


mitDat <- tibble(`All together`=reasons$high_subsets_Mito_percent, 
       `By batch`=batch.reasons$high_subsets_Mito_percent,
                 Batch=sce$DatasetName)
ph3 <- mitDat %>% 
    dplyr::filter(Batch=="HCA") %>% 
        ggvenn(show_percentage = FALSE) +
            labs(title="Mitochondrial UMIs - HCA")
pc3 <- mitDat %>% 
    dplyr::filter(Batch=="Caron") %>% 
           ggvenn(show_percentage = FALSE) +
            labs(title="Mitochondrial UMIs - Caron")

(pc1 + pc2 + pc3) / (ph1 + ph2 + ph3)
```

The most striking difference is in the filtering of the Caron data by library
size. As we can see from the violin plots the ABMMC samples from the HCA have a
radically different library size distribution to the Caron samples, with all
cells having > 1000 UMIs. When we applied the adaptive filters across all
samples, these two samples caused the MADs to be distorted and resulted in a
threshold that was inappropriately high for the Caron samples.

# QC and filtering by combining the metrics. 

In the previous approach we used the three metrics in isolation to filter
droplets. Another approach is to combine the three (or more) metrics in a single
filtering step by looking for outliers in the multi-dimensional space defined by
the metrics.

As with the adaptive thresholds above, this method should not be applied across
batches or samples with differing distributions in the metrics or it will 
exclude many good quality cells. To demonstrate these methods, we'll just 
extract one sample from our SingleCellExperiment object.

```{r}
sce.BM1 <- sce[ , sce$Sample == "ABMMC_1"]
```

## Using "outlyingness"

Essentially we need to reduce our 3 metrics to a single metric, we can then use
`isOutlier` to select outliers based on this metric. One way to do this is to
use the function `adjOutlyingness` from the `robustbase` package. This function
computes the "outlyingness" for each droplet.

Here we will use the same three metrics as before: library size, the number of
genes detected and the mitochondrial content. Remember that for "sum" (total
UMIs) and "detected" (number of genes detected), we want to use the `log10`
value.

```{r}
library(robustbase)
stats <- cbind(log10(sce.BM1$sum),
               log10(sce.BM1$detected),
               sce.BM1$subsets_Mito_percent)

outlying <- adjOutlyingness(stats, only.outlyingness = TRUE)
multi.outlier <- isOutlier(outlying, type = "higher")
summary(multi.outlier)
```

## Using PCA

Another approach is to perform a principal component analysis (PCA) on the
table of metrics, apply `adjOutlyingness` to the metrics table and use this to
detect outliers. The `scater` function `runColDataPCA` can be used to perform
the PCA and detect outliers. We'll need to add a couple of columns to the
`colData` for the log10 metrics first.

```{r}
sce.BM1$log10sum <- log10(sce.BM1$sum)
sce.BM1$log10detected <- log10(sce.BM1$detected)
sce.BM1 <- runColDataPCA(sce.BM1, 
                     variables=list("log10sum", "log10detected", "subsets_Mito_percent"),
                     outliers=TRUE,
			         BPPARAM = bp.params)
```

This has added the results of the principal component analysis into a new slot
in the SingleCellExperiment object specifically for holding the results of
dimension reduction transformations such as PCA, t-SNE and UMAP. The results
can be accessed using the `reducedDim` function.

```{r}
head(reducedDim(sce.BM1))
```

It has also added a column "outlier" to the `colData`, which specifies the 
droplets that have been identified as outliers.

```{r}
summary(sce.BM1$outlier)
```

## A note on multi-dimensional filtering

These types of approach can provide more power for detecting outliers as they
are looking at patterns across multiple metrics, however, it can be difficult to
interpret the reason why any particular droplet has been excluded.

# Mitochondrial content versus library size

A useful diagnostic plot for assessing the impact of the filtering is to do a
scatter plot of the mitochondrial content against the library size. We can 
overlay our final filter metric using the point colour.

```{r}
plotColData(sce, 
            x="sum", 
            y="subsets_Mito_percent", 
            other_fields="Sample",
            colour_by="discard") +
    facet_wrap(~Sample, ncol=5, scale="free_x")
```

# Filter low-quality cells out

We will now exclude poor-quality cells.

```{r sce_qc_ditch}
sce.Filtered <- sce[,!sce$discard]
sce.Filtered
```

We also write the R object to file to use later if need be.

```{r qc_write_rds, eval=FALSE}
saveRDS(sce.Filtered, "results/sce_filtered.rds")
```

# QC and Filtering based on sparsity

The approach above identified poor-quality using thresholds on the number of
genes detected and mitochondrial content. We will here specifically look at the
sparsity of the data, both at the gene and cell levels.

To illustrate this we will just consider the Caron samples.

```{r sparsity_split}
sce.caron <- sce[,sce$DatasetName=="Caron"]
```

## Sparsity plots

We will compute:

* the cell sparsity: for each cell, the proportion of genes that are not detected
* the gene sparsity: for each gene, the proportion of cells in which it is not detected

To help calculate the gene sparsity we can generate QC metrics for genes with
`addPerFeatureQC`. This adds two columns to the gene annotation (`rowData`):

* **mean** - the mean UMI count for the gene across all cells  
* **detected** - the percentage of cells in which the gene was detected

```{r qc_addPerFeatureQC, eval=TRUE}
sce.caron <- addPerFeatureQC(sce.caron, BPPARAM = bp.params)
head(rowData(sce.caron)) %>%
	as.data.frame() %>%
	datatable(rownames = FALSE)
```

Now we can calculate sparsity using the "detected" columns in the `colData` and 
the `rowData`.

```{r sparsity_compute}
colData(sce.caron)$cell_sparsity <- 1 - (colData(sce.caron)$detected / nrow(sce.caron))
rowData(sce.caron)$gene_sparsity <- (100 - rowData(sce.caron)$detected) / 100
```

We now plot the distribution of these two metrics.

The cell sparsity plot shows that most cells have between 85% and 99% 0's, which
is typical.

```{r}
hist(sce.caron$cell_sparsity, breaks=50, col="grey80", xlab="Cell sparsity", main="")
```

The gene sparsity plot shows that a large number of genes are almost never
detected, which is also regularly observed.

```{r}
hist(rowData(sce.caron)$gene_sparsity, breaks=50, col="grey80", xlab="Gene sparsity", main="")
```

## Filter by sparsity

We will remove cells with sparsity higher than 0.99, and/or mitochondrial
content higher than 10%.

Genes detected in a few cells only are unlikely to be informative and would
hinder normalisation. We will remove genes that are expressed in fewer than 20
cells.

```{r sparsity_filter}
sparse.cells <- sce.caron$cell_sparsity > 0.99
mito.cells <- sce.caron$subsets_Mito_percent > 10

min.cells <- 1 - (20 / ncol(sce.caron))
sparse.genes <- rowData(sce.caron)$gene_sparsity > min.cells
```

Number of genes removed:

```{r}
table(sparse.genes)
```

Number of cells removed:

```{r}
table(sparse.cells, mito.cells)
```

```{r sparsity_ditch}
sce.caron <- sce.caron[!sparse.genes, !(sparse.cells|mito.cells)]
sce.caron
```

**Note**: An important thing to note is that, now that we have filtered this
object, some of the QC metrics that we calculated across all genes (for
`colData`) and across all cells (for `rowData`) are no longer correct for the
filtered data set. We need to remove them, and if necessary recalculate them.

```{r}
colData(sce.caron) <- colData(sce.caron)[,1:3]
sce.caron <- addPerCellQC(sce.caron, BPPARAM = bp.params)
rowData(sce.caron) <- rowData(sce.caron)[,1:4]
sce.caron <- addPerFeatureQC(sce.caron, BPPARAM = bp.params)
```

# Novelty

The number of genes per UMI for each cell informs on the level of sequencing
saturation achieved (
[hbctraining](https://hbctraining.github.io/scRNA-seq_online/lessons/04_SC_quality_control.html)).
For a given cell, as sequencing depth increases each extra UMI is less likely to
correspond to a gene not already detected in that cell. Cells with small library
size tend to have higher overall 'novelty', i.e. they have not reached
saturation for any given gene. 

Here we see that some cells have fewer genes detected per UMI than in others.
This may suggest dying cell, which should be filtered out, or these might
represent a cell type with a less complex suite of genes being expressed, e.g.
red blood cells, which you may or may not wish to filter out.

```{r novelty_scat, fig.width=12, fig.height=7}
colData(sce) %>%
  as.data.frame() %>%
  arrange(subsets_Mito_percent) %>% 
  ggplot(aes(x=sum, y=detected)) + 
  geom_point(aes(color=subsets_Mito_percent)) + 
  stat_smooth(method=lm) +
  scale_x_log10() + 
  scale_y_log10() + 
  facet_wrap(vars(SampleGroup, Sample), ncol=5, dir="v")
```
We can calculate a "novelty" metrics that related the number of genes detected
to the total number of UMIs for each cell:


$\frac{\log_{10}(Number\ of\ Genes)}{\log_{10}(Number\ of\ UMIs)}$


```{r novelty_calc}
colData(sce)$log10GenesPerUMI <- log10(colData(sce)$detected) / log10(colData(sce)$sum)
```

The expected novelty is 0.8 or higher.

```{r novelty_dens, fig.width=12, fig.height=4}
colData(sce) %>%
	as.data.frame() %>%
        ggplot(aes(x=log10GenesPerUMI)) +
        geom_density(aes(color = Sample, fill = Sample), alpha=0.6) +
        facet_wrap(vars(SampleGroup), ncol=10)
```


## Session information

<details>
```{r}
sessionInfo()
```
</details>
